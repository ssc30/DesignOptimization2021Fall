{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "touched-logic",
   "metadata": {},
   "source": [
    "# Theory/Computation Problems\n",
    "\n",
    "### Problem 1 (20 points) \n",
    "Show that the stationary point (zero gradient) of the function\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    f=2x_{1}^{2} - 4x_1 x_2+ 1.5x^{2}_{2}+ x_2\n",
    "\\end{aligned}\n",
    "$$\n",
    "is a saddle (with indefinite Hessian). Find the directions of downslopes away from the saddle. Hint: Use Taylor's expansion at the saddle point. Find directions that reduce $f$.\n",
    "\n",
    "### Problem 2 (50 points) \n",
    "\n",
    "* (10 points) Find the point in the plane $x_1+2x_2+3x_3=1$ in $\\mathbb{R}^3$ that is nearest to the point $(-1,0,1)^T$. Is this a convex problem? Hint: Convert the problem into an unconstrained problem using $x_1+2x_2+3x_3=1$.\n",
    "\n",
    "* (40 points) Implement the gradient descent and Newton's algorithm for solving the problem. Attach your codes along with a short summary including (1) the initial points tested, (2) corresponding solutions, (3) a log-linear convergence plot.\n",
    "\n",
    "### Problem 3 (10 points) \n",
    "Let $f(x)$ and $g(x)$ be two convex functions defined on the convex set $\\mathcal{X}$. \n",
    "* (5 points) Prove that $af(x)+bg(x)$ is convex for $a>0$ and $b>0$. \n",
    "* (5 points) In what conditions will $f(g(x))$ be convex?\n",
    "\n",
    "### Problem 4 (bonus 10 points)\n",
    "Show that $f({\\bf x}_1) \\geq f(\\textbf{x}_0) + \n",
    "    \\textbf{g}_{\\textbf{x}_0}^T(\\textbf{x}_1-\\textbf{x}_0)$ for a convex function $f(\\textbf{x}): \\mathcal{X} \\rightarrow \\mathbb{R}$ and for $\\textbf{x}_0$, $\\textbf{x}_1 \\in \\mathcal{X}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-carbon",
   "metadata": {},
   "source": [
    "# Design Problems\n",
    "\n",
    "### Problem 5 (20 points) \n",
    "Consider an illumination problem: There are $n$ lamps and $m$ mirrors fixed to the ground. The target reflection intensity level is $I_t$. The actual reflection intensity level on the $k$th mirror can be computed as $\\textbf{a}_k^T \\textbf{p}$, where $\\textbf{a}_k$ is given by the distances between all lamps to the mirror, and $\\textbf{p}:=[p_1,...,p_n]^T$ are the power output of the lamps. The objective is to keep the actual intensity levels as close to the target as possible by tuning the power output $\\textbf{p}$.\n",
    "\n",
    "* (5 points) Formulate this problem as an optimization problem. \n",
    "* (5 points) Is your problem convex?\n",
    "* (5 points) If we require the overall power output of any of the $n$ lamps to be less than $p^*$, will the problem have a unique solution?\n",
    "* (5 points) If we require no more than half of the lamps to be switched on, will the problem have a unique solution?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d11d152e",
   "metadata": {},
   "source": [
    "# Note\n",
    "\n",
    "For this homework, you may want to attach sketches as means to explain your ideas. Here is how you can attach images.\n",
    "\n",
    "![everly1](img/everly7.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ee6b17",
   "metadata": {},
   "source": [
    "![IMG-0053](images/IMG-0053.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e208dd4",
   "metadata": {},
   "source": [
    "![IMG-0054](images/IMG-0054.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a06e87",
   "metadata": {},
   "source": [
    "![IMG-0055](images/IMG-0055.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f027d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 0.0],\n",
       " array([0.08, 0.14]),\n",
       " array([0.1352, 0.2616]),\n",
       " array([0.170288, 0.365504]),\n",
       " array([0.18939872, 0.45283776]),\n",
       " array([0.19611832, 0.52499805]),\n",
       " array([0.19350672, 0.58353264]),\n",
       " array([0.18413213, 0.63004692]),\n",
       " array([0.17011329, 0.66613339]),\n",
       " array([0.15316595, 0.69332031]),\n",
       " array([0.13465092, 0.71303616]),\n",
       " array([0.11562149, 0.72658704]),\n",
       " array([0.09686889, 0.73514421]),\n",
       " array([0.0789647 , 0.73973963]),\n",
       " array([0.06229947, 0.74126747]),\n",
       " array([0.04711743, 0.74048991]),\n",
       " array([0.0335469 , 0.73804602]),\n",
       " array([0.02162668, 0.73446245]),\n",
       " array([0.01132852, 0.73016516]),\n",
       " array([0.00257585, 0.72549155]),\n",
       " array([-0.00474072,  0.72070234]),\n",
       " array([-0.01075093,  0.71599299]),\n",
       " array([-0.01559499,  0.71150428]),\n",
       " array([-0.01941601,  0.70733202]),\n",
       " array([-0.02235425,  0.7035357 ]),\n",
       " array([-0.02454311,  0.70014605]),\n",
       " array([-0.02610632,  0.69717167]),\n",
       " array([-0.02715629,  0.69460457]),\n",
       " array([-0.02779321,  0.6924249 ]),\n",
       " array([-0.02810488,  0.69060474]),\n",
       " array([-0.02816696,  0.6891112 ]),\n",
       " array([-0.02804361,  0.68790893]),\n",
       " array([-0.02778832,  0.68696191]),\n",
       " array([-0.02744492,  0.68623493]),\n",
       " array([-0.02704862,  0.68569455]),\n",
       " array([-0.0266271 ,  0.68530981]),\n",
       " array([-0.02620157,  0.6850526 ]),\n",
       " array([-0.02578772,  0.68489789]),\n",
       " array([-0.0253967 ,  0.68482378]),\n",
       " array([-0.02503588,  0.68481142]),\n",
       " array([-0.02470966,  0.68484483]),\n",
       " array([-0.02442008,  0.68491071]),\n",
       " array([-0.02416735,  0.68499816]),\n",
       " array([-0.0239504 ,  0.68509844]),\n",
       " array([-0.02376717,  0.68520471]),\n",
       " array([-0.02361502,  0.6853117 ]),\n",
       " array([-0.02349092,  0.68541556]),\n",
       " array([-0.0233917 ,  0.68551354]),\n",
       " array([-0.02331415,  0.68560383]),\n",
       " array([-0.0232552 ,  0.68568536]),\n",
       " array([-0.02321192,  0.68575767]),\n",
       " array([-0.02318165,  0.6858207 ]),\n",
       " array([-0.02316197,  0.68587477]),\n",
       " array([-0.02315074,  0.68592038]),\n",
       " array([-0.02314611,  0.68595821]),\n",
       " array([-0.02314649,  0.68598904]),\n",
       " array([-0.02315052,  0.68601365]),\n",
       " array([-0.02315711,  0.68603286]),\n",
       " array([-0.02316534,  0.68604743]),\n",
       " array([-0.0231745 ,  0.68605811]),\n",
       " array([-0.02318402,  0.68606554]),\n",
       " array([-0.02319348,  0.68607035])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for value of a =0.01\n",
    "import numpy as np\n",
    "obj = lambda x: 5*x[0]**2+10*x[1]**2+(12*x[0]*x[1])-8*x[0]-14*x[1]+5# note that this is 1D. In Prob 2 it should be 2D.\n",
    "def grad(x):\n",
    "     return (10*x[0]+12*x[1]-8), (20*x[1]-12*x[0]-14)\n",
    "eps = 1e-3  # termination criterion  \n",
    "x0= [0.,0.]  # initial guess\n",
    "k = 0  # counter\n",
    "soln = [x0]  # use an array to store the search steps    \n",
    "x = soln[k]  # start with the initial guess\n",
    "error = np.linalg.norm(grad(x))  # compute the error. Note you will need to compute the norm for 2D grads, rather than the absolute value\n",
    "a = 0.01  # set a fixed step size to start with\n",
    "\n",
    "# Armijo line search\n",
    "def line_search(x):\n",
    "    a = 1.  # initialize step size\n",
    "    h=([[10,12],[12,20]])\n",
    "    d=-np.linalg.inv(h)*grad(x)\n",
    "    phi = lambda a, x: obj(x) - a*0.8*np.transpose(grad(x))*d  # define phi as a search criterion\n",
    "    while phi(a,x)<obj(x-a*grad(x)):  # if f(x+a*d)>phi(a) then backtrack. d is the search direction\n",
    "        a = 0.5*a\n",
    "    return a\n",
    "\n",
    "while error >= eps:  # keep searching while gradient norm is larger than eps\n",
    "    #a = line_search(x)\n",
    "    x = x - a*np.array(grad(x))\n",
    "    soln.append(x)\n",
    "    error = np.linalg.norm(grad(x))\n",
    "    \n",
    "soln  # print the search trajectory  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f01391fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 0.0],\n",
       " array([0.0625  , 0.109375]),\n",
       " array([0.10986328, 0.19580078]),\n",
       " array([0.14542389, 0.26428223]),\n",
       " array([0.17178619, 0.31872964]),\n",
       " array([0.19098449, 0.36219818]),\n",
       " array([0.20460775, 0.39707492]),\n",
       " array([0.21389699, 0.42522498]),\n",
       " array([0.2257459 , 0.47098649]),\n",
       " array([0.22716314, 0.50022586]),\n",
       " array([0.22287655, 0.52006219]),\n",
       " array([0.20820431, 0.54894461]),\n",
       " array([0.124532  , 0.61427662]),\n",
       " array([0.08599204, 0.62803184]),\n",
       " array([0.03645422, 0.67896418]),\n",
       " array([0.02045071, 0.67844123]),\n",
       " array([-0.02277453,  0.70166208]),\n",
       " array([-0.03478701,  0.71666537]),\n",
       " array([-0.05054416,  0.72192391]),\n",
       " array([-0.06039699,  0.73242714]),\n",
       " array([-0.08354146,  0.74195478]),\n",
       " array([-0.0856678 ,  0.74706109]),\n",
       " array([-0.09917469,  0.75791006]),\n",
       " array([-0.10562305,  0.7599035 ]),\n",
       " array([-0.10953627,  0.76424141]),\n",
       " array([-0.11897805,  0.76794228]),\n",
       " array([-0.11977577,  0.77009513]),\n",
       " array([-0.12519875,  0.77452096]),\n",
       " array([-0.12784025,  0.77526882]),\n",
       " array([-0.12939171,  0.77706298]),\n",
       " array([-0.13131913,  0.77777804]),\n",
       " array([-0.13383727,  0.78031164]),\n",
       " array([-0.13462999,  0.78030584]),\n",
       " array([-0.13680127,  0.78148622]),\n",
       " array([-0.13741514,  0.78222939]),\n",
       " array([-0.13820272,  0.78250401]),\n",
       " array([-0.13870403,  0.78302604]),\n",
       " array([-0.13986305,  0.78351698]),\n",
       " array([-0.13997472,  0.78376751]),\n",
       " array([-0.14065759,  0.78431081]),\n",
       " array([-0.1409797 ,  0.78441549]),\n",
       " array([-0.14117901,  0.7846309 ]),\n",
       " array([-0.1416516 ,  0.78482215]),\n",
       " array([-0.14169378,  0.78492766]),\n",
       " array([-0.14196804,  0.78514919]),\n",
       " array([-0.14209991,  0.78518873]),\n",
       " array([-0.14217902,  0.78527775]),\n",
       " array([-0.14227544,  0.78531483]),\n",
       " array([-0.14240338,  0.78544092]),\n",
       " array([-0.14244267,  0.78544161])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gradient Method\n",
    "import numpy as np\n",
    "obj = lambda x: 5*x[0]**2+10*x[1]**2+(12*x[0]*x[1])-8*x[0]-14*x[1]+5# note that this is 1D. In Prob 2 it should be 2D.\n",
    "def grad(x):\n",
    "     return np.array([10*x[0]+12*x[1]-8, 20*x[1]+12*x[0]-14])\n",
    "eps = 1e-3  # termination criterion  \n",
    "x0= [0.,0.]  # initial guess\n",
    "k = 0  # counter\n",
    "soln = [x0]  # use an array to store the search steps    \n",
    "x = soln[k]  # start with the initial guess\n",
    "error = np.linalg.norm(grad(x))  # compute the error. Note you will need to compute the norm for 2D grads, rather than the absolute value\n",
    "#a = 0.01  # set a fixed step size to start with\n",
    "\n",
    "\n",
    "# Armijo line search\n",
    "def line_search(x):\n",
    "    a = 1.  # initialize step size\n",
    "    d=-grad(x)\n",
    "    phi = lambda a, x: obj(x) + a*0.8*np.dot(grad(x),d)  # define phi as a search criterion\n",
    "    while phi(a,x)<obj(x-a*grad(x)):  # if f(x+a*d)>phi(a) then backtrack. d is the search direction\n",
    "        a = 0.5*a\n",
    "    return a\n",
    "\n",
    "while error >= eps:  # keep searching while gradient norm is larger than eps\n",
    "    a = line_search(x)\n",
    "    x = x - a*np.array(grad(x))\n",
    "    soln.append(x)\n",
    "    error = np.linalg.norm(grad(x))\n",
    "    \n",
    "soln  # print the search trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d5bf363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 0]),\n",
       " array([-0.03571429,  0.19642857]),\n",
       " array([-0.0625 ,  0.34375]),\n",
       " array([-0.08258929,  0.45424107]),\n",
       " array([-0.09765625,  0.53710938]),\n",
       " array([-0.10895647,  0.5992606 ]),\n",
       " array([-0.11743164,  0.64587402]),\n",
       " array([-0.12378802,  0.68083409]),\n",
       " array([-0.1285553 ,  0.70705414]),\n",
       " array([-0.13213076,  0.72671918]),\n",
       " array([-0.13481236,  0.74146795]),\n",
       " array([-0.13682355,  0.75252954]),\n",
       " array([-0.13833195,  0.76082572]),\n",
       " array([-0.13946325,  0.76704786]),\n",
       " array([-0.14031172,  0.77171447]),\n",
       " array([-0.14094808,  0.77521442]),\n",
       " array([-0.14142534,  0.77783939]),\n",
       " array([-0.14178329,  0.77980811]),\n",
       " array([-0.14205176,  0.78128466]),\n",
       " array([-0.1422531 ,  0.78239206]),\n",
       " array([-0.14240411,  0.78322262]),\n",
       " array([-0.14251737,  0.78384554]),\n",
       " array([-0.14260231,  0.78431272]),\n",
       " array([-0.14266602,  0.78466311]),\n",
       " array([-0.1427138 ,  0.78492591]),\n",
       " array([-0.14274964,  0.785123  ]),\n",
       " array([-0.14277651,  0.78527082]),\n",
       " array([-0.14279667,  0.78538169]),\n",
       " array([-0.14281179,  0.78546484]),\n",
       " array([-0.14282313,  0.7855272 ]),\n",
       " array([-0.14283163,  0.78557397]),\n",
       " array([-0.14283801,  0.78560905]),\n",
       " array([-0.14284279,  0.78563536]),\n",
       " array([-0.14284638,  0.78565509]),\n",
       " array([-0.14284907,  0.78566989])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Newton Method\n",
    "import numpy as np\n",
    "obj = lambda x: (2-2*x[0]-3*x[1])**2 + x[0]**2 +(x[1]-1)**2# note that this is 1D. In Prob 2 it should be 2D.\n",
    "def grad(x):\n",
    "     return np.array([10*x[0]+12*x[1]-8, 20*x[1]+12*x[0]-14])\n",
    "h=([[10,12],[12,20]])\n",
    "eps = 1e-3  # termination criterion  \n",
    "x0= np.zeros((2),dtype=int)  # initial guess\n",
    "k = 0  # counter\n",
    "soln = [x0]  # use an array to store the search steps    \n",
    "x = soln[k]  # start with the initial guess\n",
    "error = np.linalg.norm(grad(x))  # compute the error. Note you will need to compute the norm for 2D grads, rather than the absolute value\n",
    "a = 1  # set a fixed step size to start with\n",
    "\n",
    "# Armijo line search\n",
    "def line_search(x):\n",
    "    a = 1.  # initialize step size\n",
    "    d=-np.matmul(np.linalg.inv(h),grad(x))    \n",
    "    phi = lambda a, x: obj(x) + a*0.8*np.dot(grad(x),d)  # define phi as a search criterion\n",
    "    while phi(a,x)<obj(x+a*d):  # while phi(a,x)<obj(x-a*grad(x)): # if f(x+a*d)>phi(a) then backtrack. d is the search direction\n",
    "        a = 0.5*a\n",
    "    return a\n",
    "\n",
    "while error >= eps:  # keep searching while gradient norm is larger than eps\n",
    "    a = line_search(x)\n",
    "    d=-np.matmul(np.linalg.inv(h),grad(x))\n",
    "    x = x+a*d\n",
    "    soln.append(x)\n",
    "    error = np.linalg.norm(grad(x))\n",
    "    \n",
    "soln  # print the search trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17a2fb9",
   "metadata": {},
   "source": [
    "![IMG-0056](images/IMG-0056.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402f36c0",
   "metadata": {},
   "source": [
    "![IMG-0057](images/IMG-0057.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6e6e70",
   "metadata": {},
   "source": [
    "![IMG-0058](images/IMG-0058.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411a23b3",
   "metadata": {},
   "source": [
    "![IMG-0059](images/IMG-0059.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf6f64a",
   "metadata": {},
   "source": [
    "![IMG-0060](images/IMG-0060.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c23239",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
